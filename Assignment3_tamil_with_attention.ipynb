{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_tamil_with_attention.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13116932ecc6445985bd133c2ce9af16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cce0de430d242a0be4c7f02e75eaae0",
              "IPY_MODEL_a8a7737af2eb4f7085133e13a0409b43"
            ],
            "layout": "IPY_MODEL_9519b1dc645546d8bd9cbae2d0302da6"
          }
        },
        "7cce0de430d242a0be4c7f02e75eaae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e41c21e2bc48138646f84c6d1d5742",
            "placeholder": "​",
            "style": "IPY_MODEL_a6646280bd994248921fd362cd466dde",
            "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "a8a7737af2eb4f7085133e13a0409b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c5481c5d4d4485ab59019a49cd0928",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c45c09762d634c6aa45dc3f48b9d42ed",
            "value": 1
          }
        },
        "9519b1dc645546d8bd9cbae2d0302da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e41c21e2bc48138646f84c6d1d5742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6646280bd994248921fd362cd466dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20c5481c5d4d4485ab59019a49cd0928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c45c09762d634c6aa45dc3f48b9d42ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb2e2188cd0c46fb9e1e9c9001bf71c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68c808140a5a419eb3d783809680f62a",
              "IPY_MODEL_76f9f1b3bf9c45beb3fcfb7552702edb"
            ],
            "layout": "IPY_MODEL_d968e33621b641949f61d5a6b67f045f"
          }
        },
        "68c808140a5a419eb3d783809680f62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3442c7d1ca44c6b7712ba5c6ed73bb",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac72d376e3b4d459dd2d454559a5ab4",
            "value": ""
          }
        },
        "76f9f1b3bf9c45beb3fcfb7552702edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63c95cce6d834139af207827cf9bda1e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_875fab669c2c43e2a5da031d33068a6a",
            "value": 0
          }
        },
        "d968e33621b641949f61d5a6b67f045f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3442c7d1ca44c6b7712ba5c6ed73bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac72d376e3b4d459dd2d454559a5ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c95cce6d834139af207827cf9bda1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875fab669c2c43e2a5da031d33068a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandVP123/q1/blob/main/Assignment3_tamil_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQR-UXPvy6XZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import io\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "import keras.backend as K\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from random import randint\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import array_equal\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1pLA9mDzGxD",
        "outputId": "a23ade80-ce87-4db8-bd69-2c4006cf336f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-08 23:49:54--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 108.177.98.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   250MB/s    in 7.8s    \n",
            "\n",
            "2022-05-08 23:50:02 (246 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfUYhTACzQSS",
        "outputId": "0e9b0e4e-00e1-4cfb-a3eb-37ec058ae5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 11.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 50.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of data"
      ],
      "metadata": {
        "id": "YzVnQQt_F850"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We had chosen tamil language for transliteration\n",
        "td = \"lexicon-dataset/ta.translit.sampled.train.tsv\"\n",
        "dd = \"lexicon-dataset/ta.translit.sampled.dev.tsv\"\n",
        "testd = \"lexicon-dataset/ta.translit.sampled.test.tsv\"\n",
        "def data_pre(cf):\n",
        "  tamil_words = []\n",
        "  latin_words = []\n",
        "  with io.open(cf, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      tamil_words.append(tokens[0])\n",
        "  return latin_words, tamil_words\n",
        "src_train, tgt_train = data_pre(td)\n",
        "print(\"Training Samples: \", len(src_train))\n",
        "src_val, tgt_val = data_pre(dd)\n",
        "src_test, tgt_test = data_pre(testd)\n",
        "print(\"Validation Samples: \", len(src_val))\n",
        "print(\"Testing Samples: \", len(src_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCCzzVFxzVjh",
        "outputId": "f89f9047-0bbc-472d-e3c9-8d06fa0a3b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  68218\n",
            "Number of validation samples:  6827\n",
            "Number of testing samples:  6864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We had chosen tamil language for transliteration\n",
        "td = \"lexicon-dataset/ta.translit.sampled.train.tsv\"\n",
        "dd = \"lexicon-dataset/ta.translit.sampled.dev.tsv\"\n",
        "testd = \"lexicon-dataset/ta.translit.sampled.test.tsv\"\n",
        "def data_pre(cf):\n",
        "  tamil_words = []\n",
        "  latin_words = []\n",
        "  with io.open(cf, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      tamil_words.append(tokens[0])\n",
        "  return latin_words, tamil_words\n",
        "src_train, tgt_train = data_pre(td)\n",
        "print(\"Training Samples: \", len(src_train))\n",
        "src_val, tgt_val = data_pre(dd)\n",
        "print(\"Validation Samples: \", len(src_val))\n",
        "src_test, tgt_test = data_pre(testd)\n",
        "print(\"Testing Samples: \", len(src_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89f9047-0bbc-472d-e3c9-8d06fa0a3b94",
        "id": "Pus-azU8DFRO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  68218\n",
            "Number of validation samples:  6827\n",
            "Number of testing samples:  6864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(len(src_train))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(src_val))\n",
        "np.random.shuffle(arr1)\n",
        "ip_char = set()\n",
        "tgt_char = set()\n",
        "ip_txt = []\n",
        "tgt_txt = []\n",
        "valip_txt = []\n",
        "valtgt_txt = []\n",
        "for (ip_txt, tgt_txt) in zip(src_train, tgt_train):\n",
        "    tgt_txt = \"B\" + tgt_txt + \"E\"\n",
        "    ip_txt.append(input_text)\n",
        "    tgt_txt.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in ip_char:\n",
        "            ip_char.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in tgt_char:\n",
        "            tgt_char.add(char)\n",
        "for (input_text, target_text) in zip(src_val, tgt_val):\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    valip_txt.append(input_text)\n",
        "    valtgt_txt.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in ip_char:\n",
        "            ip_char.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in tgt_char:\n",
        "            tgt_char.add(char)\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "for i in range(len(src_train)):\n",
        "    input_texts.append(ip_txt[arr[i]])\n",
        "    target_texts.append(tgt_txt[arr[i]])\n",
        "val_ip_txt = []\n",
        "val_tgt_txt = []\n",
        "for i in range(len(src_val)):\n",
        "    val_ip_txt.append(valip_txt[arr1[i]])\n",
        "    val_tgt_txt.append(valtgt_txt[arr1[i]])\n",
        "ip_char.add(\" \")\n",
        "tgt_char.add(\" \")\n",
        "ip_char = sorted(list(ip_char))\n",
        "tgt_char = sorted(list(tgt_char))\n",
        "en_tkn = len(ip_char)\n",
        "de_tkn = len(tgt_char)\n",
        "max_enlen = max([len(txt) for txt in input_texts])\n",
        "max_delen = max([len(txt) for txt in target_texts])\n",
        "val_enlen = max([len(txt) for txt in val_ip_txt])\n",
        "val_delen = max([len(txt) for txt in val_tgt_txt])\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", en_tkn)\n",
        "print(\"Number of unique output tokens:\", de_tkn)\n",
        "#print(\"Max sequence length for inputs:\", max_enlen)\n",
        "#print(\"Max sequence length for outputs:\", max_delen)\n",
        "#print(\"Max sequence length for val inputs:\", val_enlen)\n",
        "#print(\"Max sequence length for val outputs:\", val_delen)\n",
        "print(ip_char)\n",
        "print(tgt_char)"
      ],
      "metadata": {
        "id": "X8YtefJhzbKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iptkn_ind = dict([(char, i) for i, char in enumerate(ip_char)])\n",
        "tgttkn_ind = dict([(char, i) for i, char in enumerate(tgt_char)])\n",
        "print(iptkn_ind)\n",
        "print(tgttkn_ind)"
      ],
      "metadata": {
        "id": "qIfSLo0QzfDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trc_ip_txt = input_texts[:68096]\n",
        "trc_tgt_txt = target_texts[:68096]\n",
        "en_ip_data = np.zeros(\n",
        "    (len(trc_ip_txt), max_enlen, en_tkn), dtype=\"float64\"\n",
        ")\n",
        "de_tgt_data = np.zeros(\n",
        "    (len(trc_ip_txt), max_delen, de_tkn), dtype=\"float64\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(trc_ip_txt, trc_tgt_txt)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        en_ip_data[i, t, iptkn_ind[char]] = 1.0\n",
        "    en_ip_data[i, t + 1 :, iptkn[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        de_tgt_data[i, t, tgtkn_ind[char]] = 1.0\n",
        "    de_tgt_data[i, t + 1 :, tgtkn_ind[\" \"]] = 1.0\n",
        "val_en_in_data = np.zeros(\n",
        "    (len(val_input_texts), max_enlen, en_tkn), dtype=\"float64\"\n",
        ")\n",
        "val_de_tgt_data = np.zeros(\n",
        "    (len(val_target_texts), max_delen, de_tkn), dtype=\"float64\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(val_ip_txt, val_tgt_txt)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_en_ip_data[i, t, iptkn_ind[char]] = 1.0\n",
        "    val_en_ip_data[i, t + 1 :, iptkn_ind[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        val_de_tgt_data[i, t, tgtkn_ind[char]] = 1.0\n",
        "        val_de_tgt_data[i, t + 1: ,tgtkn_ind[\" \"]] = 1.0"
      ],
      "metadata": {
        "id": "5TixmNMCzgH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def init_attn(self, units):\n",
        "    super(BahdanauAttention, self).init_attn()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "  def call(self, query, values):\n",
        "    timeaxis_query = tf.expand_dims(query, 1)\n",
        "    score = self.V(tf.nn.tanh(self.W1(timeaxis_query) + self.W2(values)))\n",
        "    attn_wts = tf.nn.softmax(score, axis=1)\n",
        "    cntx_vr = attention_weights * values\n",
        "    cntx_vr = tf.reduce_sum(cntx_vr, axis=1)\n",
        "    return cntx_vr, attn_wts"
      ],
      "metadata": {
        "id": "qXM2XO-pzkm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def init_attn(self, units):\n",
        "    super(LuongAttention, self).init_attn()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "  def call(self, query, values):\n",
        "    timeaxis_query = tf.expand_dims(query, 1)\n",
        "    transp_value = tf.transpose(values, perm=[0, 2, 1])\n",
        "    score = tf.transpose(tf.matmul(timeaxis_query, transp_value) , perm=[0, 2, 1])\n",
        "    attn_wts = tf.nn.softmax(score, axis=1)\n",
        "    cntx_vr = atn_wts * values\n",
        "    cntx_vr = tf.reduce_sum(cntx_vr, axis=1)\n",
        "    return cntx_vr, attn_wts"
      ],
      "metadata": {
        "id": "r7KxB4OWzrfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attn_rnn(object):\n",
        "  def init_attn(self,cell_type = 'RNN', hidden_size=32, \n",
        "               learning_rate= 1e-3,dropout=0.3,epochs = 10, batch_size = 32,\n",
        "               attn = 'bahdanau'):\n",
        "        self.cell_type = cell_type\n",
        "    self.hidden_size = hidden_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attn = attention\n",
        "  def fit(self,en_ip_data,de_tgt_data):\n",
        "    en_ip = Input(shape=(max_enlen, en_tkn), name='en_ip')\n",
        "    if self.cell_type == 'LSTM':\n",
        "      en_lstm = LSTM(self.hidden_size,return_seq=True, return_st=True, dropout = self.dropout, name='en_lstm')\n",
        "      en_op, en_st_h, en_st_c = en_lstm(en_in)\n",
        "      en_st = [en_st_h, en_st_c]\n",
        "    elif self.cell_type == 'GRU':\n",
        "      en_gru = GRU(self.hidden_size,return_seq=True, return_st=True, dropout = self.dropout, name='en_gru')\n",
        "      en_op, en_st_h = en_gru(en_ip)\n",
        "      en_st = [en_st_h]\n",
        "    elif self.cell_type == 'RNN':\n",
        "      en_rnn = SimpleRNN(self.hidden_size,return_seq=True, return_st=True, dropout = self.dropout, name='en_rnn')\n",
        "      en_op, en_st_h = en_rnn(en_ip)\n",
        "      en_st = [en_st_h]\n",
        "\n",
        "    # Setting up of attention layer\n",
        "    if self.attn == 'bahdanau':\n",
        "      attention= BahdanauAttention(self.hidden_size)\n",
        "    elif self.attention == 'luong':\n",
        "      attention= LuongAttention(self.hidden_size)\n",
        "    # Decoder layer setup\n",
        "    de_ip = Input(shape=(1, (de_tkn+self.hidden_size)),name='de_ip')\n",
        "    if self.cell_type == 'LSTM':\n",
        "      de_lstm = LSTM(self.hidden_size, dropout = self.dropout, return_st=True, name='de_lstm')\n",
        "    elif self.cell_type == 'GRU':\n",
        "      de_gru = GRU(self.hidden_size, dropout = self.dropout, return_st=True, name='de_gru')\n",
        "    elif self.cell_type == 'RNN':\n",
        "      de_rnn = SimpleRNN(self.hidden_size, dropout = self.dropout, return_st=True, name='de_rnn')  \n",
        "    de_dense = Dense(de_tkn, activation='softmax',  name='de_dense')\n",
        "    all_op = []\n",
        "    inputs = np.zeros((self.batch_size, 1, de_tkn))\n",
        "    inputs[:, 0, 0] = 1 \n",
        "    de_op = en_st_h\n",
        "    states = en_st\n",
        "    for _ in range(max_delen):\n",
        "      cntx_vr, attn_wts=attention(de_op, en_op)   \n",
        "      cntx_vr = tf.expand_dims(cntx_vr, 1)\n",
        "      inputs = tf.concat([cntx_vr, inputs], axis=-1)\n",
        "      if self.cell_type == 'LSTM':\n",
        "        de_op, st_h, st_c = de_lstm(inputs, initial_st=states)\n",
        "      if self.cell_type == 'GRU':\n",
        "        de_op, st_h = de_gru(inputs, initial_st=states)\n",
        "      if self.cell_type == 'RNN':\n",
        "        de_op, st_h = de_rnn(inputs, initial_st=states)\n",
        "      outputs = de_dense(de_op)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_op.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell_type == 'LSTM':\n",
        "        states = [st_h, st_c]\n",
        "      if self.cell_type == 'GRU' or self.cell_type == 'RNN':\n",
        "        states = [st_h]\n",
        "    de_op = Lambda(lambda x: K.concatenate(x, axis=1))(all_op)\n",
        "    ####getindicelayer = Lambda(lambda x: x[:, -1, :]) \n",
        "    #de_outputs = getindicelayer(all_op)\n",
        "    model = Model(en_ip, de_op, name='model_encoder_decoder')  \n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    ##model.summary()\n",
        "    model.fit(en_ip_data, de_tgt_data,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.epochs,\n",
        "              callbacks = [WandbCallback()])\n",
        "    pred=model.predict(val_en_ip_data[:6784], batch_size=self.batch_size)\n",
        "    global_count = 0\n",
        "    count = 0\n",
        "    global_total = 0\n",
        "    global_correct = 0\n",
        "    val_total = 6784\n",
        "    for index in range(0, val_total):\n",
        "      one_hot_vector = pred[index]\n",
        "      one_hot_vector1 = val_de_tgt_data[index]\n",
        "      index2 = tf.argmax(one_hot_vector, axis=1)\n",
        "      index1 = tf.argmax(one_hot_vector1, axis=1)\n",
        "        if (index2.numpy() == index1.numpy()).all():\n",
        "        global_correct = global_correct + 1    \n",
        "      global_total = global_total + 1\n",
        "      accuracy_epoch = global_correct/global_total\n",
        "      if global_total % 50 == 0:\n",
        "        wandb.log({'epoch_accuracy' : accuracy_epoch}\n",
        "    val_accuracy = global_correct/global_total\n",
        "    wandb.log({'val_accuracy' : val_accuracy})\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "VPMbA5Tjzy2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sweep_training():\n",
        "  config_defaults = {\n",
        "        'dropout': 0.3,\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 128,\n",
        "        'epochs' : 15,\n",
        "        'hidden_size': 128,\n",
        "        'cell_type': 'LSTM',\n",
        "        'attention': 'bahdanau'\n",
        "        }\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(config = config_defaults)\n",
        "  config = wandb.config\n",
        "  wandb.run.name = str(config.cell_type)+ '_' + config.attention +'_bs_'+str(config.batch_size)\n",
        "    model_rnn = attn_rnn(cell_type = config.cell_type, hidden_size=config.hidden_size,\n",
        "                learning_rate= config.learning_rate, dropout=config.dropout,epochs = config.epochs,\n",
        "                batch_size = config.batch_size, attention = config.attention)\n",
        "    model_rnn.fit(en_ip_data,de_tgt_data)"
      ],
      "metadata": {
        "id": "jvFgEi-Y0Hkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_sweep = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'batch_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "       \n",
        "        'hidden_size':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['RNN', 'GRU', 'LSTM']\n",
        "        },\n",
        "        'attention': {\n",
        "            'values': ['bahdanau', 'luong']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "MV0qIcahz_sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(param_sweep, entity=\"ee20d064oe21d019\", project=\"cs6910_a3\")\n",
        "wandb.agent(sweep_id, sweep_training,count=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13116932ecc6445985bd133c2ce9af16",
            "7cce0de430d242a0be4c7f02e75eaae0",
            "a8a7737af2eb4f7085133e13a0409b43",
            "9519b1dc645546d8bd9cbae2d0302da6",
            "81e41c21e2bc48138646f84c6d1d5742",
            "a6646280bd994248921fd362cd466dde",
            "20c5481c5d4d4485ab59019a49cd0928",
            "c45c09762d634c6aa45dc3f48b9d42ed",
            "bb2e2188cd0c46fb9e1e9c9001bf71c2",
            "68c808140a5a419eb3d783809680f62a",
            "76f9f1b3bf9c45beb3fcfb7552702edb",
            "d968e33621b641949f61d5a6b67f045f",
            "4a3442c7d1ca44c6b7712ba5c6ed73bb",
            "4ac72d376e3b4d459dd2d454559a5ab4",
            "63c95cce6d834139af207827cf9bda1e",
            "875fab669c2c43e2a5da031d33068a6a",
            "28c59479333949a484cca94cfbbf2265"
          ]
        },
        "id": "5X6tSMLS0RPB",
        "outputId": "a79b2147-01db-4c9c-9e8b-b18fff6035f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 9r1cb7c2\n",
            "Sweep URL: https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 97btb3mu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: bahdanau\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mavp\u001b[0m (\u001b[33mee20d064oe21d019\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_085313-97btb3mu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/97btb3mu\" target=\"_blank\">restful-sweep-1</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "532/532 [==============================] - 96s 125ms/step - loss: 1.0751 - accuracy: 0.6987\n",
            "Epoch 2/15\n",
            "532/532 [==============================] - 67s 126ms/step - loss: 0.8183 - accuracy: 0.7468\n",
            "Epoch 3/15\n",
            "532/532 [==============================] - 67s 125ms/step - loss: 0.6646 - accuracy: 0.7951\n",
            "Epoch 4/15\n",
            "532/532 [==============================] - 67s 126ms/step - loss: 0.5918 - accuracy: 0.8214\n",
            "Epoch 5/15\n",
            "532/532 [==============================] - 66s 123ms/step - loss: 0.5562 - accuracy: 0.8349\n",
            "Epoch 6/15\n",
            "532/532 [==============================] - 66s 124ms/step - loss: 0.5321 - accuracy: 0.8433\n",
            "Epoch 7/15\n",
            "532/532 [==============================] - 67s 125ms/step - loss: 0.5180 - accuracy: 0.8479\n",
            "Epoch 8/15\n",
            "532/532 [==============================] - 66s 124ms/step - loss: 0.5097 - accuracy: 0.8508\n",
            "Epoch 9/15\n",
            "532/532 [==============================] - 67s 126ms/step - loss: 0.4964 - accuracy: 0.8546\n",
            "Epoch 10/15\n",
            "532/532 [==============================] - 65s 123ms/step - loss: 0.4909 - accuracy: 0.8564\n",
            "Epoch 11/15\n",
            "532/532 [==============================] - 65s 122ms/step - loss: 0.4858 - accuracy: 0.8576\n",
            "Epoch 12/15\n",
            "532/532 [==============================] - 65s 122ms/step - loss: 0.4774 - accuracy: 0.8601\n",
            "Epoch 13/15\n",
            "532/532 [==============================] - 67s 125ms/step - loss: 0.4757 - accuracy: 0.8609\n",
            "Epoch 14/15\n",
            "532/532 [==============================] - 67s 125ms/step - loss: 0.4661 - accuracy: 0.8640\n",
            "Epoch 15/15\n",
            "532/532 [==============================] - 66s 124ms/step - loss: 0.4634 - accuracy: 0.8648\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13116932ecc6445985bd133c2ce9af16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>▁▅▃▂▃▅▆▇▇▇▇█████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>0.44074</td></tr><tr><td>val_accuracy</td><td>0.4406</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">restful-sweep-1</strong>: <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/97btb3mu\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/97btb3mu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_085313-97btb3mu/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: loz1mg6s with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: bahdanau\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_091143-loz1mg6s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/loz1mg6s\" target=\"_blank\">woven-sweep-2</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1064/1064 [==============================] - 223s 170ms/step - loss: 1.1277 - accuracy: 0.6920\n",
            "Epoch 2/15\n",
            "1064/1064 [==============================] - 180s 170ms/step - loss: 0.9105 - accuracy: 0.7261\n",
            "Epoch 3/15\n",
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.5468 - accuracy: 0.8352\n",
            "Epoch 4/15\n",
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.3713 - accuracy: 0.9039\n",
            "Epoch 5/15\n",
            "1002/1064 [===========================>..] - ETA: 10s - loss: 0.3289 - accuracy: 0.9164"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.3290 - accuracy: 0.9164\n",
            "Epoch 6/15\n",
            " 271/1064 [======>.......................] - ETA: 2:13 - loss: 0.3209 - accuracy: 0.9188"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 611/1064 [================>.............] - ETA: 1:16 - loss: 0.3122 - accuracy: 0.9208"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.3062 - accuracy: 0.9221\n",
            "Epoch 7/15\n",
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.2857 - accuracy: 0.9272\n",
            "Epoch 8/15\n",
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.2758 - accuracy: 0.9293\n",
            "Epoch 9/15\n",
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.2614 - accuracy: 0.9329\n",
            "Epoch 10/15\n",
            "1064/1064 [==============================] - 179s 169ms/step - loss: 0.2520 - accuracy: 0.9351\n",
            "Epoch 11/15\n",
            "1064/1064 [==============================] - 179s 168ms/step - loss: 0.2460 - accuracy: 0.9366\n",
            "Epoch 12/15\n",
            "1064/1064 [==============================] - 179s 168ms/step - loss: 0.2388 - accuracy: 0.9383\n",
            "Epoch 13/15\n",
            "1064/1064 [==============================] - 179s 168ms/step - loss: 0.2357 - accuracy: 0.9391\n",
            "Epoch 14/15\n",
            "1064/1064 [==============================] - 179s 168ms/step - loss: 0.2284 - accuracy: 0.9411\n",
            "Epoch 15/15\n",
            "1064/1064 [==============================] - 180s 169ms/step - loss: 0.2230 - accuracy: 0.9425\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb2e2188cd0c46fb9e1e9c9001bf71c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>▂▅▂▁▂▅▅▆▇▆▇▇▇███▇▇▇▆▆▆▆▆▇▇▇▇██▇▇███▇▇▇▇▇</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>0.44785</td></tr><tr><td>val_accuracy</td><td>0.44723</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">woven-sweep-2</strong>: <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/loz1mg6s\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/loz1mg6s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_091143-loz1mg6s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rzsz19ly with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: luong\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_095839-rzsz19ly</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/rzsz19ly\" target=\"_blank\">vocal-sweep-3</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1064/1064 [==============================] - 205s 153ms/step - loss: 1.3848 - accuracy: 0.6648\n",
            "Epoch 2/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 1.0603 - accuracy: 0.6965\n",
            "Epoch 3/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 1.0387 - accuracy: 0.6988\n",
            "Epoch 4/15\n",
            "1064/1064 [==============================] - 164s 155ms/step - loss: 1.0292 - accuracy: 0.6998\n",
            "Epoch 5/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 1.0220 - accuracy: 0.7005\n",
            "Epoch 6/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 1.0144 - accuracy: 0.7014\n",
            "Epoch 7/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 1.0039 - accuracy: 0.7028\n",
            "Epoch 8/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 0.9870 - accuracy: 0.7062\n",
            "Epoch 9/15\n",
            "1064/1064 [==============================] - 164s 155ms/step - loss: 0.9632 - accuracy: 0.7108\n",
            "Epoch 10/15\n",
            "1064/1064 [==============================] - 164s 155ms/step - loss: 0.9374 - accuracy: 0.7155\n",
            "Epoch 11/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 0.9059 - accuracy: 0.7210\n",
            "Epoch 12/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 0.8675 - accuracy: 0.7281\n",
            "Epoch 13/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 0.8276 - accuracy: 0.7363\n",
            "Epoch 14/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 0.7904 - accuracy: 0.7459\n",
            "Epoch 15/15\n",
            "1064/1064 [==============================] - 165s 155ms/step - loss: 0.7565 - accuracy: 0.7561\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28c59479333949a484cca94cfbbf2265"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>▁▁▁▁▁▄▄▄▃▃▅▆▇▆▇▇▇▆▆▆▆▅▆▇█▇▇▇▇▇▆███▇▇▇▇█▇</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>0.00222</td></tr><tr><td>val_accuracy</td><td>0.00221</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">vocal-sweep-3</strong>: <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/rzsz19ly\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/rzsz19ly</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_095839-rzsz19ly/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9jeh1i87 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: bahdanau\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_104134-9jeh1i87</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/9jeh1i87\" target=\"_blank\">fragrant-sweep-4</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/9r1cb7c2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "532/532 [==============================] - 84s 108ms/step - loss: 1.5950 - accuracy: 0.6439\n",
            "Epoch 2/15\n",
            "532/532 [==============================] - 57s 108ms/step - loss: 1.1307 - accuracy: 0.6924\n",
            "Epoch 3/15\n",
            "532/532 [==============================] - 58s 108ms/step - loss: 1.0774 - accuracy: 0.6975\n",
            "Epoch 4/15\n",
            "532/532 [==============================] - 58s 108ms/step - loss: 1.0531 - accuracy: 0.6994\n",
            "Epoch 5/15\n",
            "532/532 [==============================] - 57s 108ms/step - loss: 1.0379 - accuracy: 0.7012\n",
            "Epoch 6/15\n",
            "532/532 [==============================] - 57s 107ms/step - loss: 1.0251 - accuracy: 0.7030\n",
            "Epoch 7/15\n",
            "532/532 [==============================] - 57s 107ms/step - loss: 1.0126 - accuracy: 0.7047\n",
            "Epoch 8/15\n",
            "532/532 [==============================] - 57s 106ms/step - loss: 1.0010 - accuracy: 0.7062\n",
            "Epoch 9/15\n",
            "532/532 [==============================] - 56s 106ms/step - loss: 0.9900 - accuracy: 0.7080\n",
            "Epoch 10/15\n",
            "532/532 [==============================] - 57s 108ms/step - loss: 0.9795 - accuracy: 0.7094\n",
            "Epoch 11/15\n",
            "532/532 [==============================] - 57s 107ms/step - loss: 0.9679 - accuracy: 0.7117\n",
            "Epoch 12/15\n",
            " 97/532 [====>.........................] - ETA: 46s - loss: 0.9648 - accuracy: 0.7121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attn_plot(self,attention, sequence, predicted_sequence, idx,fig): \n",
        "    ax = fig.add_subplot(4, 3, idx)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 16}\n",
        "    seq = ''\n",
        "    for i in range(len(sequence)):\n",
        "      seq = seq + reverse_src_char_ind[sequence[i]]  \n",
        "    pred = ''\n",
        "    for i in range(len(pred_seq)):\n",
        "      pred = pred + reverse_tgt_char_ind[pred_seq[i]]\n",
        "##\n",
        "    ax.set_xticklabels(seq, fontdict=fontdict)\n",
        "    ax.set_yticklabels(pred, fontdict=fontdict, fontproperties = tamil_font)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  def trans(self,seq_in, idx,fig):\n",
        "    seq_in, seq_out, attn_plot, w_attn = self.evaluate(seq_in)\n",
        "    a = [0]\n",
        "    for i in range(len(seq_in)):\n",
        "      if seq_in[i] != 0:\n",
        "        a.append(seq_in[i])\n",
        "    b = []\n",
        "    for i in range(len(seq_out)):\n",
        "      if seq_out[i] != 0:\n",
        "        b.append(seq_out[i])\n",
        "    b = b[:len(b)-1] \n",
        "    attn_plot = attn_plot[:len(b), :len(a)]\n",
        "    self.plot_attn(attn_plot, a, b, idx,fig)  \n",
        "    return w_attn\n",
        "  def attn_plot(self,val_input):\n",
        "    w_a = []\n",
        "    fig = plt.figure(figsize=(16,18))\n",
        "    for i in range(1,13,1): \n",
        "      seq_in = val_ip[i*9]\n",
        "      w_attn = self.trans(seq_in,i,fig)  \n",
        "      w_a.append(w_attn)\n",
        "    plt.show()\n",
        "    return w_a"
      ],
      "metadata": {
        "id": "0iWqm7jLsL2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "1M8tYWTKsUC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = attn_rnn(cell_type = 'LSTM', hidden_size=128, learning_rate= 1e-3,\n",
        "                        dropout=0.2,epochs = 2, batch_size = 128, attention = 'bahdanau')\n",
        "\n",
        "encoder,attention,decoder,de_dense = model_rnn.fit(en_ip_data,de_tgt_data)"
      ],
      "metadata": {
        "id": "MuBiN8fj0lFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MQZaDMcssdw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.fit(en_ip_data,de_tgt_data)"
      ],
      "metadata": {
        "id": "CnC84rYB0mc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "f8738a57-36d1-4999-c9d6-0e51f7e20e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "532/532 [==============================] - 173s 240ms/step - loss: 1.1431 - accuracy: 0.6876\n",
            "Epoch 2/2\n",
            "532/532 [==============================] - 127s 239ms/step - loss: 0.9789 - accuracy: 0.7074\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7889794b57c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-1cfad31f6d91>\u001b[0m in \u001b[0;36mbuild_fit\u001b[0;34m(self, encoder_input_data, decoder_target_data)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_correct\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mglobal_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mglobal_total\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch_accuracy'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0maccuracy_epoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m       \u001b[0;31m#print(\"Accuracy: %s\" % (accuracy_epoch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connectivity visualization\n",
        "def connectivity(s, color=None):\n",
        "  # Function to get text html element\n",
        "  if color is None:\n",
        "      return '''<text style=\"padding:2px; color:#C0C0C0\"> {} </text>'''.format(s)\n",
        "  return '''<text style=\"color:#000;background-color:{}; padding:2px; color:#FF6699\"> {} </text>'''.format(color, s)"
      ],
      "metadata": {
        "id": "Uzc21jF-fC_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connectivity_plot(input, pr_out, pr_scores, attn_scores, de_char_ind=0):\n",
        "    <table style=\"border:2px solid black; border-collapse:collapse; font-size:1.5em\">\n",
        "    <caption> <strong>INPUT : </strong> {} </caption>\n",
        "    <tr>\n",
        "    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Character in Prediction Focussed </th>\n",
        "    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Attention Visualization </th>\n",
        "    </tr>\n",
        "    '''.format(input)\n",
        "    for k in range(K):  \n",
        "        char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else '&lt end &gt' if dec_char_ind == len(pred_out[k]) else '&lt blank &gt'\n",
        "        middle_char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else ''\n",
        "        end_str = pred_out[k][dec_char_ind+1:] if dec_char_ind < len(pred_out[k])-1 else ''\n",
        "        html_str += '''\n",
        "        <tr>\n",
        "        <td style=\"border:1px solid black;padding:10px;text-align:center\"> character at index {} of {}<span style=\"color: #FF1493\">{}</span>{} <br/> ({}) </td>\n",
        "        <td style=\"border:1px solid black;padding:10px;text-align:center\">\n",
        "        '''.format(dec_char_ind, pred_out[k][:dec_char_ind], middle_char, end_str, char)\n",
        "        for i,c in enumerate(input):\n",
        "            html_str += '''\n",
        "            {}\n",
        "            '''.format(cstr(c, get_clr(attn_scores[k,dec_char_ind,i], 'YlGnBu')))\n",
        "        html_str += '''\n",
        "        </td>\n",
        "        </tr>\n",
        "        '''\n",
        "    html_str += '''\n",
        "    </table>\n",
        "    '''\n",
        "    display(html_print(html_str))"
      ],
      "metadata": {
        "id": "Ss07lh_mfQWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_viz_attn(sample_ind=0, de_char_ind=0):\n",
        "    connectivity_plot(test_inp[sample_ind], test2_pr_out[sample_ind], test2_pr_scores[sample_ind], test2_attn_scores[sample_ind], de_char_ind)"
      ],
      "metadata": {
        "id": "hPaEyhNKfTDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}