{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Assignment 3 vanilla model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "294b3350c0f74c5aa43585ae3992f8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6a961aa5de040a4b471325c9808421f",
              "IPY_MODEL_ac2a979a2b884b86ba61fb0b2eabce76"
            ],
            "layout": "IPY_MODEL_114ca8c0878e4735a6977abd76dc4338"
          }
        },
        "a6a961aa5de040a4b471325c9808421f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1efd7df17c943838e0f8995d062ec86",
            "placeholder": "​",
            "style": "IPY_MODEL_b571b058437d44208e68bda378a2d41c",
            "value": "3.682 MB of 3.682 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "ac2a979a2b884b86ba61fb0b2eabce76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36128b57ff1242679c6e9c324a0d87ea",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78411982bb67442d8abbb301679649d3",
            "value": 1
          }
        },
        "114ca8c0878e4735a6977abd76dc4338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1efd7df17c943838e0f8995d062ec86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b571b058437d44208e68bda378a2d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36128b57ff1242679c6e9c324a0d87ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78411982bb67442d8abbb301679649d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9726796829541a6b2f421ae17a0536f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bbb8428302243e3977abed86c8236e5",
              "IPY_MODEL_b4a0045da8aa42bba206ec5aa9bb99e3"
            ],
            "layout": "IPY_MODEL_02970d6c55c84f01b4f4ac6a12e0910f"
          }
        },
        "0bbb8428302243e3977abed86c8236e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb010e33ac64fe7949d4b0938856505",
            "placeholder": "​",
            "style": "IPY_MODEL_f261c8ca1df74280a7f3f09c955f4960",
            "value": "5.493 MB of 5.493 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b4a0045da8aa42bba206ec5aa9bb99e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f30da3d6f990420ca632bb249e1f11b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f266d7953574a02b1ef142a7cb7195b",
            "value": 1
          }
        },
        "02970d6c55c84f01b4f4ac6a12e0910f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb010e33ac64fe7949d4b0938856505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f261c8ca1df74280a7f3f09c955f4960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f30da3d6f990420ca632bb249e1f11b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f266d7953574a02b1ef142a7cb7195b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandVP123/q1/blob/main/Final_Assignment_3_vanilla_model_tamil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ5BwqDIYSP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2dab8d4-2035-4fc5-95c2-c28ae64ccab5"
      },
      "source": [
        "##installing wandb\n",
        "!pip install wandb\n",
        "##dowloading dakshin data set\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "##dakshin dataset\n",
        "!tar -xf dakshina_dataset_v1.0.tar\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ea126a966627aecee3b0de715072b5ef8a9b6073b8181f14cbee6072fbdfb5f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.16\n",
            "--2022-05-08 15:47:56--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 74.125.204.128, 64.233.187.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   151MB/s    in 14s     \n",
            "\n",
            "2022-05-08 15:48:10 (140 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wtNj_IqYrW5"
      },
      "source": [
        "\n",
        "##########processingdakshin\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "##Defineclass\n",
        "class DP():\n",
        "    def __init__(self, DATAPATH, source_lang = 'en', target_lang = \"ta\"):\n",
        "        self.source_lang = source_lang\n",
        "        self.target_lang = target_lang\n",
        "        self.trainpath = os.path.join(DATAPATH, target_lang, \"lexicons\", target_lang+\".translit.sampled.train.tsv\")\n",
        "        self.valpath = os.path.join(DATAPATH, target_lang, \"lexicons\", target_lang+\".translit.sampled.dev.tsv\")\n",
        "        self.testpath = os.path.join(DATAPATH, target_lang, \"lexicons\", target_lang+\".translit.sampled.test.tsv\")\n",
        "        self.train = pd.read_csv(self.trainpath,sep=\"\\t\",names=[\"tgt\", \"src\", \"count\"],)\n",
        "        self.val = pd.read_csv(self.valpath,sep=\"\\t\",names=[\"tgt\", \"src\", \"count\"],)\n",
        "        self.test = pd.read_csv(self.testpath,sep=\"\\t\",names=[\"tgt\", \"src\", \"count\"],)\n",
        "        ##Traijning of Data & creating val/test data \n",
        "        self.traindata = self.preprocess(self.train[\"src\"].to_list(), self.train[\"tgt\"].to_list())\n",
        "        (self.trencoderinput,self.train_decoder_input,self.train_decoder_target,self.source_vocab,self.target_vocab,) = self.traindata\n",
        "        self.so_chartoint, self.source_int2char = self.source_vocab\n",
        "        self.tar_chartoint, self.target_int2char = self.target_vocab\n",
        "        self.valdata = self.encode(self.val[\"src\"].to_list(),self.val[\"tgt\"].to_list(),list(self.so_chartoint.keys()),list(self.tar_chartoint.keys()),so_chartoint=self.so_chartoint,tar_chartoint=self.tar_chartoint,)\n",
        "        self.valencoderinput, self.val_decoder_input, self.val_decoder_target = self.valdata\n",
        "        self.so_chartoint, self.source_int2char = self.source_vocab\n",
        "        self.tar_chartoint, self.target_int2char = self.target_vocab\n",
        "        self.testdata = self.encode(self.test[\"src\"].to_list(),self.test[\"tgt\"].to_list(),list(self.so_chartoint.keys()),list(self.tar_chartoint.keys()),so_chartoint=self.so_chartoint,tar_chartoint=self.tar_chartoint,)\n",
        "        self.testencoderinput, self.test_decoder_input, self.test_decoder_target = self.testdata\n",
        "        self.so_chartoint, self.source_int2char = self.source_vocab\n",
        "        self.tar_chartoint, self.target_int2char = self.target_vocab\n",
        "    def dictionary_lookup(self, vocab):\n",
        "        char2int = dict([(char, i) for i, char in enumerate(vocab)])\n",
        "        int2char = dict((i, char) for char, i in char2int.items())\n",
        "        return char2int, int2char\n",
        "    def encode(self, source, target, source_chars, target_chars, so_chartoint=None, tar_chartoint=None):\n",
        "        num_encoder_tokens = len(source_chars)\n",
        "        numdecodertok = len(target_chars)\n",
        "        sourcelengthmax = max([len(txt) for txt in source])\n",
        "        targetlength = max([len(txt) for txt in target])\n",
        "        source_vocab, target_vocab = None, None\n",
        "        if so_chartoint == None and tar_chartoint == None:\n",
        "            print(\"Generating the dictionary lookups for character to integer mapping and back\")\n",
        "            so_chartoint, source_int2char = self.dictionary_lookup(source_chars)\n",
        "            tar_chartoint, target_int2char = self.dictionary_lookup(target_chars)\n",
        "            source_vocab = (so_chartoint, source_int2char)\n",
        "            target_vocab = (tar_chartoint, target_int2char)\n",
        "        encoderindata = np.zeros((len(source), sourcelengthmax, num_encoder_tokens), dtype=\"float32\")\n",
        "        decoderindata = np.zeros((len(source), targetlength, numdecodertok), dtype=\"float32\")\n",
        "        decodertardata = np.zeros((len(source), targetlength, numdecodertok), dtype=\"float32\")\n",
        "        for i, (input_text, target_text) in enumerate(zip(source, target)):\n",
        "            for t, char in enumerate(input_text):\n",
        "                encoderindata[i, t, so_chartoint[char]] = 1.0\n",
        "            encoderindata[i, t + 1 :, so_chartoint[\" \"]] = 1.0\n",
        "            for t, char in enumerate(target_text):\n",
        "                decoderindata[i, t, tar_chartoint[char]] = 1.0\n",
        "                if t > 0:\n",
        "                    decodertardata[i, t - 1, tar_chartoint[char]] = 1.0\n",
        "            decoderindata[i, t + 1 :, tar_chartoint[\" \"]] = 1.0\n",
        "            decodertardata[i, t:, tar_chartoint[\" \"]] = 1.0\n",
        "        if source_vocab != None and target_vocab != None:return (encoderindata,decoderindata,decodertardata,source_vocab,target_vocab,)\n",
        "        else:return encoderindata, decoderindata, decodertardata\n",
        "    def preprocess(self, source , target):\n",
        "        source_chars = set()\n",
        "        target_chars = set()\n",
        "        source = [str(x) for x in source]\n",
        "        target = [str(x) for x in target]\n",
        "        source_words = []\n",
        "        target_words = []\n",
        "        for src, tgt in zip(source, target):\n",
        "            tgt = \"\\t\" + tgt + \"\\n\"\n",
        "            source_words.append(src)\n",
        "            target_words.append(tgt)\n",
        "            for char in src:\n",
        "                if char not in source_chars:\n",
        "                    source_chars.add(char)\n",
        "            for char in tgt:\n",
        "                if char not in target_chars:\n",
        "                    target_chars.add(char)\n",
        "        source_chars = sorted(list(source_chars))\n",
        "        target_chars = sorted(list(target_chars))\n",
        "        source_chars.append(\" \")\n",
        "        target_chars.append(\" \")\n",
        "        num_encoder_tokens = len(source_chars)\n",
        "        print(\"Source Vocab length:\", num_encoder_tokens)\n",
        "        numdecodertok = len(target_chars)\n",
        "        print(\"Target Vocab length:\", numdecodertok)\n",
        "        sourcelengthmax = max([len(txt) for txt in source_words])\n",
        "        print(\"Max sequence length for inputs:\", sourcelengthmax)\n",
        "        targetlength = max([len(txt) for txt in target_words])\n",
        "        print(\"Max sequence length for outputs:\", targetlength)\n",
        "        print(\"Number of samples:\", len(source))\n",
        "        return self.encode(source_words, target_words, source_chars, target_chars)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-kjn6OdZVkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c452e1b3-8bee-447d-80eb-0d7c7ac3ec56"
      },
      "source": [
        "#####processesing db for tamil\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "DATAPATH = \"./dakshina_dataset_v1.0\"\n",
        "dataBase = DP(DATAPATH) \n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Vocab length: 27\n",
            "Target Vocab length: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n",
            "Number of samples: 68218\n",
            "Generating the dictionary lookups for character to integer mapping and back\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT83-HQ3Z5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "bbfbe860-2596-4b4f-c919-542889ea2cbc"
      },
      "source": [
        "####RNN\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Activation, LSTM, SimpleRNN, GRU, TimeDistributed\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model, Sequential,  Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "class Sequence2Sequence():\n",
        "    def __init__(self, modelConfigDict, srcChar2Int, tgtChar2Int, using_pretrained_model = False):\n",
        "        #self.native_vocabulary = modelConfigDict[\"native_vocabulary\"]\n",
        "        self.nE = modelConfigDict[\"nE\"]\n",
        "        self.ct = modelConfigDict[\"ct\"]\n",
        "        self.ld = modelConfigDict[\"ld\"]\n",
        "        self.dout = modelConfigDict[\"dout\"]\n",
        "        self.nD = modelConfigDict[\"nD\"]\n",
        "        self.hidden = modelConfigDict[\"hidden\"]\n",
        "        self.tgtChar2Int = tgtChar2Int\n",
        "        self.srcChar2Int = srcChar2Int\n",
        "    ## encoder & decoder\n",
        "    def build_configurable_model(self):       \n",
        "    if self.ct == \"RNN\":\n",
        "    einput = Input(shape=(None, len(self.srcChar2Int)))\n",
        "    eout = einput\n",
        "    for i in range(1, self.nE + 1):\n",
        "    encoder = SimpleRNN(self.ld,retstate=True,retsequence=True,dout=self.dout,)\n",
        "    eout, state = encoder(einput)estate = [state]\n",
        "    dinput = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "   doutput = dinput\n",
        "    for i in range(1, self.nD + 1):decoder = SimpleRNN(self.ld, retsequence=True, retstate=True, dout=self.dout,)\n",
        "   doutput, _ = decoder(dinput, initial_state=estate)\n",
        "  hidden = Dense(self.hidden, activation=\"relu\")\n",
        "  hidoutput = hidden(decoder_outputs)\n",
        "  ddense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "  doutput = ddense(hidoutput)\n",
        "  model = Model([einput, dinput],doutput)\n",
        " return model\n",
        "elif self.ct == \"LSTM\":\n",
        "einput = Input(shape=(None, len(self.srcChar2Int)))\n",
        "eout = einput\n",
        "for i in range(1, self.nE + 1):\n",
        "encoder = LSTM(self.ld,retstate=True,retsequence=True,dout=self.dout,)\n",
        "eout, state_h, state_c = encoder(eout)\n",
        "estate = [state_h, state_c]\n",
        "dinput = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "doutput = dinput\n",
        "for i in range(1, self.nD + 1):\n",
        "decoder = LSTM(self.ld,retstate=True,retsequence=True,dout=self.dout,)\n",
        "doutput, _, _ = decoder(doutput, initial_state=estate)\n",
        "### dense\n",
        "hidden = Dense(self.hidden, activation=\"relu\")\n",
        "hidoutput = hidden(decoder_outputs)\n",
        "ddense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "doutput = ddense(hidoutput)\n",
        "model = Model([einput, dinput],doutput)\n",
        "return model\n",
        "elif self.ct == \"GRU\":\n",
        "einput = Input(shape=(None, len(self.srcChar2Int)))\n",
        "eout = einput\n",
        "for i in range(1, self.nE + 1):\n",
        "encoder = GRU(self.ld,retstate=True,retsequence=True,dout=self.dout,)\n",
        "eout, state = encoder(einput)\n",
        "estate = [state]\n",
        "dinput = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "doutput = dinput\n",
        "for i in range(1, self.nD + 1):\n",
        "decoder = GRU(self.ld,retsequence=True,retstate=True,dout=self.dout,)\n",
        "doutput, _ = decoder(dinput, initial_state=estate)\n",
        "hidden = Dense(self.hidden, activation=\"relu\")\n",
        "hidoutput = hidden(decoder_outputs)\n",
        "ddense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "doutput = ddense(hidoutput)\n",
        "model = Model([einput, dinput],doutput)\n",
        "return model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-001c2625a8bf>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    if self.ct == \"RNN\":\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-B1RkORaHjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "233a98cc-36b9-42aa-fef6-0ba68b9e4350"
      },
      "source": [
        "##model training\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import RNN, LSTM, GRU, Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except: pass\n",
        "def train():\n",
        "config_defaults = {\"ct\": \"RNN\",\"ld\": 256,\"hidden\": 128,\"optimiser\": \"rmsprop\",\"nE\": 1,\"nD\": 1,\"dout\": 0.2,\"epochs\": 1,\"batchsize\": 64,}\n",
        "##wandbinit\n",
        "wandb.init(config=config_defaults,  project=\"cs6910_a3\", entity=\"ee20d064oe21d019\")\n",
        "config = wandb.config\n",
        "wandb.run.name = (str(config.ct)\n",
        "        + dataBase.source_lang\n",
        "        + str(config.nE)\n",
        "        + \"_\"\n",
        "        + dataBase.target_lang\n",
        "        + \"_\"\n",
        "        + str(config.nD)\n",
        "        + \"_\"\n",
        "        + config.optimiser\n",
        "        + \"_\"\n",
        "        + str(config.epochs)\n",
        "        + \"_\"\n",
        "        + str(config.dout) \n",
        "        + \"_\"\n",
        "        + str(config.batchsize)\n",
        "        + \"_\"\n",
        "        + str(config.ld))\n",
        "    wandb.run.save()\n",
        "modelInit = Sequence2Sequence(config,srcChar2Int=dataBase.so_chartoint, tgtChar2Int=dataBase.tar_chartoint)\n",
        "model = modelInit.build_configurable_model()\n",
        "model.summary()\n",
        "model.compile(optimizer=config.optimiser,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],)\n",
        "earlystopping = EarlyStopping(\n",
        "monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=2, mode=\"auto\")\n",
        "model.fit([dataBase.trencoderinput, dataBase.train_decoder_input],dataBase.train_decoder_target,batchsize=config.batchsize,epochs=config.epochs,validation_data=([dataBase.valencoderinput, dataBase.val_decoder_input], dataBase.val_decoder_target),callbacks=[earlystopping, WandbCallback()],)\n",
        "model.save(os.DATAPATH.join(\"./TrainedModels\", wandb.run.name))    \n",
        "wandb.finish()\n",
        "return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-040444cfad51>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    config_defaults = {\"ct\": \"RNN\",\"ld\": 256,\"hidden\": 128,\"optimiser\": \"rmsprop\",\"nE\": 1,\"nD\": 1,\"dout\": 0.2,\"epochs\": 1,\"batchsize\": 64,}\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xeopy2fZacpG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "e4c5d161-4d11-40f4-aa4c-c26e01de1447"
      },
      "source": [
        "'''    \n",
        "sweep_config = {\n",
        "    \"name\": \"Bayesian Sweep without attention\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "         \"ct\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "         \"ld\": {\"values\": [256]},\n",
        "         \"hidden\": {\"values\": [128, 64]},\n",
        "         \"optimiser\": {\"values\": [\"rmsprop\", \"adam\"]},\n",
        "         \"nE\": {\"values\": [1, 2, 3]},\n",
        "         \"nD\": {\"values\": [1, 2, 3]},\n",
        "         \"dout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "         \"epochs\": {\"values\": [5,10,15]},\n",
        "         \"batchsize\": {\"values\": [32, 64]},},}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"cs6910_a3\", entity=\"ee20d064oe21d019\")\n",
        "wandb.agent(sweep_id, train)\n",
        "\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    \\nsweep_config = {\\n    \"name\": \"Bayesian Sweep without attention\",\\n    \"method\": \"bayes\",\\n    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\\n    \"parameters\": {\\n        \\n        \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\\n        \\n        \"latentDim\": {\"values\": [256]},\\n        \\n        \"hidden\": {\"values\": [128, 64]},\\n        \\n        \"optimiser\": {\"values\": [\"rmsprop\", \"adam\"]},\\n        \\n        \"numEncoders\": {\"values\": [1, 2, 3]},\\n        \\n        \"numDecoders\": {\"values\": [1, 2, 3]},\\n        \\n        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\\n        \\n        \"epochs\": {\"values\": [5,10,15]},\\n        \\n        \"batch_size\": {\"values\": [32, 64]},\\n    },\\n}\\n\\nsweep_id = wandb.sweep(sweep_config, project=\"cs6910_a3\", entity=\"ee20d064oe21d019\")\\n\\nwandb.agent(sweep_id, train)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbZXjvV9agMF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "294b3350c0f74c5aa43585ae3992f8a2",
            "a6a961aa5de040a4b471325c9808421f",
            "ac2a979a2b884b86ba61fb0b2eabce76",
            "114ca8c0878e4735a6977abd76dc4338",
            "d1efd7df17c943838e0f8995d062ec86",
            "b571b058437d44208e68bda378a2d41c",
            "36128b57ff1242679c6e9c324a0d87ea",
            "78411982bb67442d8abbb301679649d3",
            "b9726796829541a6b2f421ae17a0536f",
            "0bbb8428302243e3977abed86c8236e5",
            "b4a0045da8aa42bba206ec5aa9bb99e3",
            "02970d6c55c84f01b4f4ac6a12e0910f",
            "deb010e33ac64fe7949d4b0938856505",
            "f261c8ca1df74280a7f3f09c955f4960",
            "f30da3d6f990420ca632bb249e1f11b5",
            "6f266d7953574a02b1ef142a7cb7195b"
          ]
        },
        "outputId": "079ff6d1-1189-44d2-d703-289d5a338269"
      },
      "source": [
        "  \n",
        "sweep_config = {\n",
        "    \"name\": \"Bayesian Sweep without attention\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "                \"ct\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "                \"ld\": {\"values\": [256]},\n",
        "                \"hidden\": {\"values\": [128, 64]},\n",
        "                \"optimiser\": {\"values\": [\"rmsprop\", \"adam\"]},\n",
        "                \"nE\": {\"values\": [1, 2, 3]},\n",
        "                \"nD\": {\"values\": [1, 2, 3]},\n",
        "                \"dout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "                \"epochs\": {\"values\": [5,10,15, 20]},\n",
        "                \"batchsize\": {\"values\": [32, 64]},\n",
        "    },}\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"cs6910_a3\", entity=\"ee20d064oe21d019\")\n",
        "wandb.agent(sweep_id, train, count = 200)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: fzu4vby8\n",
            "Sweep URL: https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kwe31qoz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mavp\u001b[0m (\u001b[33mee20d064oe21d019\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_134208-kwe31qoz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/kwe31qoz\" target=\"_blank\">clear-sweep-1</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 49)]   0           []                               \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, None, 256),  218880      ['input_1[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " gru_4 (GRU)                    [(None, None, 256),  235776      ['input_2[0][0]',                \n",
            "                                 (None, 256)]                     'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 64)     16448       ['gru_4[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 49)     3185        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 474,289\n",
            "Trainable params: 474,289\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1066/1066 [==============================] - 41s 31ms/step - loss: 0.8220 - accuracy: 0.7668 - val_loss: 1.4630 - val_accuracy: 0.7097 - _timestamp: 1652017379.0000 - _runtime: 51.0000\n",
            "Epoch 2/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.6102 - accuracy: 0.8192 - val_loss: 1.4818 - val_accuracy: 0.7381 - _timestamp: 1652017412.0000 - _runtime: 84.0000\n",
            "Epoch 3/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.4657 - accuracy: 0.8608 - val_loss: 1.5851 - val_accuracy: 0.7616 - _timestamp: 1652017443.0000 - _runtime: 115.0000\n",
            "Epoch 4/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.3644 - accuracy: 0.8924 - val_loss: 1.5068 - val_accuracy: 0.7862 - _timestamp: 1652017475.0000 - _runtime: 147.0000\n",
            "Epoch 5/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.3106 - accuracy: 0.9088 - val_loss: 1.6111 - val_accuracy: 0.7875 - _timestamp: 1652017507.0000 - _runtime: 179.0000\n",
            "Epoch 6/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.2752 - accuracy: 0.9193 - val_loss: 1.6867 - val_accuracy: 0.7851 - _timestamp: 1652017539.0000 - _runtime: 211.0000\n",
            "Epoch 7/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.2527 - accuracy: 0.9258 - val_loss: 1.7193 - val_accuracy: 0.7937 - _timestamp: 1652017571.0000 - _runtime: 243.0000\n",
            "Epoch 8/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.2355 - accuracy: 0.9308 - val_loss: 1.8337 - val_accuracy: 0.7824 - _timestamp: 1652017603.0000 - _runtime: 275.0000\n",
            "Epoch 9/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.2222 - accuracy: 0.9343 - val_loss: 1.7710 - val_accuracy: 0.7977 - _timestamp: 1652017635.0000 - _runtime: 307.0000\n",
            "Epoch 10/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.2106 - accuracy: 0.9379 - val_loss: 1.8255 - val_accuracy: 0.7920 - _timestamp: 1652017667.0000 - _runtime: 339.0000\n",
            "Epoch 11/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.2025 - accuracy: 0.9399 - val_loss: 1.8364 - val_accuracy: 0.8025 - _timestamp: 1652017699.0000 - _runtime: 371.0000\n",
            "Epoch 12/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.1948 - accuracy: 0.9422 - val_loss: 1.8326 - val_accuracy: 0.7978 - _timestamp: 1652017731.0000 - _runtime: 403.0000\n",
            "Epoch 13/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.1879 - accuracy: 0.9442 - val_loss: 1.8825 - val_accuracy: 0.7935 - _timestamp: 1652017762.0000 - _runtime: 434.0000\n",
            "Epoch 14/20\n",
            "1066/1066 [==============================] - 32s 30ms/step - loss: 0.1825 - accuracy: 0.9457 - val_loss: 1.9145 - val_accuracy: 0.7997 - _timestamp: 1652017794.0000 - _runtime: 466.0000\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedModels/GRUen3_ta_2_rmsprop_20_0.2_64_256/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedModels/GRUen3_ta_2_rmsprop_20_0.2_64_256/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7739779dd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f76babb7850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='3.668 MB of 3.668 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "294b3350c0f74c5aa43585ae3992f8a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▆▇▇▇▇██████</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▆▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▇▇▇▇▆█▇██▇█</td></tr><tr><td>val_loss</td><td>▁▁▃▂▃▄▅▇▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94568</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.46302</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>loss</td><td>0.18253</td></tr><tr><td>val_accuracy</td><td>0.79974</td></tr><tr><td>val_loss</td><td>1.9145</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">clear-sweep-1</strong>: <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/kwe31qoz\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/kwe31qoz</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_134208-kwe31qoz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kjyp7k11 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_135009-kjyp7k11</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/kjyp7k11\" target=\"_blank\">jumping-sweep-2</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 49)]   0           []                               \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, None, 256),  218880      ['input_1[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    [(None, None, 256),  235776      ['input_2[0][0]',                \n",
            "                                 (None, 256)]                     'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 64)     16448       ['gru_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 49)     3185        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 474,289\n",
            "Trainable params: 474,289\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "1066/1066 [==============================] - 36s 30ms/step - loss: 0.8506 - accuracy: 0.7611 - val_loss: 1.7995 - val_accuracy: 0.6725 - _timestamp: 1652017851.0000 - _runtime: 42.0000\n",
            "Epoch 2/20\n",
            "1066/1066 [==============================] - 29s 27ms/step - loss: 0.6542 - accuracy: 0.8054 - val_loss: 1.7551 - val_accuracy: 0.7010 - _timestamp: 1652017881.0000 - _runtime: 72.0000\n",
            "Epoch 3/20\n",
            "1066/1066 [==============================] - 29s 27ms/step - loss: 0.4884 - accuracy: 0.8553 - val_loss: 1.6459 - val_accuracy: 0.7384 - _timestamp: 1652017909.0000 - _runtime: 100.0000\n",
            "Epoch 4/20\n",
            "1066/1066 [==============================] - 29s 27ms/step - loss: 0.3735 - accuracy: 0.8899 - val_loss: 1.7195 - val_accuracy: 0.7438 - _timestamp: 1652017938.0000 - _runtime: 129.0000\n",
            "Epoch 5/20\n",
            "1066/1066 [==============================] - 29s 28ms/step - loss: 0.3129 - accuracy: 0.9080 - val_loss: 1.6104 - val_accuracy: 0.7644 - _timestamp: 1652017968.0000 - _runtime: 159.0000\n",
            "Epoch 6/20\n",
            "1066/1066 [==============================] - 28s 27ms/step - loss: 0.2768 - accuracy: 0.9187 - val_loss: 1.6477 - val_accuracy: 0.7652 - _timestamp: 1652017996.0000 - _runtime: 187.0000\n",
            "Epoch 7/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.2522 - accuracy: 0.9258 - val_loss: 1.6251 - val_accuracy: 0.7712 - _timestamp: 1652018023.0000 - _runtime: 214.0000\n",
            "Epoch 8/20\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.2336 - accuracy: 0.9311 - val_loss: 1.5769 - val_accuracy: 0.7833 - _timestamp: 1652018051.0000 - _runtime: 242.0000\n",
            "Epoch 9/20\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.2195 - accuracy: 0.9351 - val_loss: 1.6426 - val_accuracy: 0.7749 - _timestamp: 1652018079.0000 - _runtime: 270.0000\n",
            "Epoch 10/20\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.2081 - accuracy: 0.9384 - val_loss: 1.6069 - val_accuracy: 0.7846 - _timestamp: 1652018106.0000 - _runtime: 297.0000\n",
            "Epoch 11/20\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.1996 - accuracy: 0.9409 - val_loss: 1.6071 - val_accuracy: 0.7890 - _timestamp: 1652018134.0000 - _runtime: 325.0000\n",
            "Epoch 12/20\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.1908 - accuracy: 0.9434 - val_loss: 1.6663 - val_accuracy: 0.7873 - _timestamp: 1652018162.0000 - _runtime: 353.0000\n",
            "Epoch 13/20\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.1852 - accuracy: 0.9448 - val_loss: 1.6467 - val_accuracy: 0.7840 - _timestamp: 1652018190.0000 - _runtime: 381.0000\n",
            "Epoch 13: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedModels/GRUen3_ta_1_adam_20_0.2_64_256/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedModels/GRUen3_ta_1_adam_20_0.2_64_256/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7690700410> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f76ba0a6210> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='5.480 MB of 5.480 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9726796829541a6b2f421ae17a0536f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▆▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▆▄▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▅▇▇▇█▇████</td></tr><tr><td>val_loss</td><td>█▇▃▅▂▃▃▁▃▂▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94481</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>1.57688</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>loss</td><td>0.18522</td></tr><tr><td>val_accuracy</td><td>0.784</td></tr><tr><td>val_loss</td><td>1.64673</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">jumping-sweep-2</strong>: <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/kjyp7k11\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/kjyp7k11</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_135009-kjyp7k11/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k6h5z4ng with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_135658-k6h5z4ng</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/runs/k6h5z4ng\" target=\"_blank\">balmy-sweep-3</a></strong> to <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8\" target=\"_blank\">https://wandb.ai/ee20d064oe21d019/cs6910_a3/sweeps/fzu4vby8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, None, 256),  290816      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 49)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['lstm[0][0]']                   \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 256),  313344      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 256),  525312      ['lstm_2[0][0]',                 \n",
            "                                 (None, 256),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, None, 256),  525312      ['lstm_3[0][0]',                 \n",
            "                                 (None, 256),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 64)     16448       ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 49)     3185        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,199,729\n",
            "Trainable params: 2,199,729\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "1066/1066 [==============================] - 82s 68ms/step - loss: 0.8313 - accuracy: 0.7648 - val_loss: 1.5194 - val_accuracy: 0.7283 - _timestamp: 1652018307.0000 - _runtime: 89.0000\n",
            "Epoch 2/15\n",
            "1066/1066 [==============================] - 69s 65ms/step - loss: 0.4284 - accuracy: 0.8733 - val_loss: 1.8043 - val_accuracy: 0.7412 - _timestamp: 1652018376.0000 - _runtime: 158.0000\n",
            "Epoch 3/15\n",
            "1066/1066 [==============================] - 70s 66ms/step - loss: 0.2728 - accuracy: 0.9197 - val_loss: 1.7477 - val_accuracy: 0.7660 - _timestamp: 1652018446.0000 - _runtime: 228.0000\n",
            "Epoch 4/15\n",
            "1066/1066 [==============================] - 70s 66ms/step - loss: 0.2086 - accuracy: 0.9392 - val_loss: 1.7937 - val_accuracy: 0.7809 - _timestamp: 1652018516.0000 - _runtime: 298.0000\n",
            "Epoch 5/15\n",
            "1066/1066 [==============================] - 70s 66ms/step - loss: 0.1735 - accuracy: 0.9495 - val_loss: 1.8547 - val_accuracy: 0.7835 - _timestamp: 1652018587.0000 - _runtime: 369.0000\n",
            "Epoch 6/15\n",
            "1066/1066 [==============================] - 70s 66ms/step - loss: 0.1502 - accuracy: 0.9561 - val_loss: 1.8871 - val_accuracy: 0.7890 - _timestamp: 1652018657.0000 - _runtime: 439.0000\n",
            "Epoch 7/15\n",
            "1066/1066 [==============================] - 70s 65ms/step - loss: 0.1335 - accuracy: 0.9608 - val_loss: 1.9675 - val_accuracy: 0.7888 - _timestamp: 1652018726.0000 - _runtime: 508.0000\n",
            "Epoch 8/15\n",
            "1066/1066 [==============================] - 70s 65ms/step - loss: 0.1208 - accuracy: 0.9645 - val_loss: 1.9749 - val_accuracy: 0.7997 - _timestamp: 1652018796.0000 - _runtime: 578.0000\n",
            "Epoch 9/15\n",
            "1066/1066 [==============================] - 70s 65ms/step - loss: 0.1110 - accuracy: 0.9672 - val_loss: 2.0204 - val_accuracy: 0.7904 - _timestamp: 1652018866.0000 - _runtime: 648.0000\n",
            "Epoch 10/15\n",
            " 494/1066 [============>.................] - ETA: 36s - loss: 0.1043 - accuracy: 0.9690"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNbxAtkQ1yC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b21564a-e61f-4b43-9c73-53eec11ae008"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp -rf ./TrainedModels /content/gdrive/MyDrive/CS6910/Assignment3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    }
  ]
}